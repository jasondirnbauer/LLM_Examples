{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0b463d54",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gemini Response:\n",
      "\n",
      "Of course! Let's explain decision trees using a simple analogy.\n",
      "\n",
      "### The \"20 Questions\" Game Analogy\n",
      "\n",
      "Imagine you're playing the game \"20 Questions.\" Your friend is thinking of an animal, and you have to guess what it is by asking only yes/no questions.\n",
      "\n",
      "Your first question wouldn't be \"Is it a squirrel?\" That's too specific. A good first question would be something broad, like:\n",
      "\n",
      "*   **You:** \"Does it live in the water?\"\n",
      "*   **Friend:** \"No.\"\n",
      "\n",
      "Okay, you've just eliminated all fish, whales, octopuses, etc. You've split the \"world of animals\" into two big groups and discarded one.\n",
      "\n",
      "Your next question might be:\n",
      "\n",
      "*   **You:** \"Does it have fur?\"\n",
      "*   **Friend:** \"Yes.\"\n",
      "\n",
      "Great! Now you've narrowed it down to mammals. You've split your remaining group again.\n",
      "\n",
      "You continue this process, asking questions that split your remaining options until you're confident you know the answer. You might end up with a path like this:\n",
      "\n",
      "*   Does it live in water? → **No**\n",
      "*   Does it have fur? → **Yes**\n",
      "*   Does it bark? → **Yes**\n",
      "*   **Conclusion: It's a dog!**\n",
      "\n",
      "You've just built a decision tree in your head!\n",
      "\n",
      "---\n",
      "\n",
      "### What is a Decision Tree in Machine Learning?\n",
      "\n",
      "A decision tree is a model that works exactly like the \"20 Questions\" game. It's a flowchart of questions that the computer learns to ask to arrive at a conclusion.\n",
      "\n",
      "It's used for two main tasks:\n",
      "1.  **Classification:** Predicting a category (e.g., \"Dog,\" \"Cat,\" \"Fish\").\n",
      "2.  **Regression:** Predicting a numerical value (e.g., the price of a house).\n",
      "\n",
      "Let's look at the parts of a decision tree.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "*   **Root Node:** The very first question you ask. This is the most important question that splits your data best. (e.g., \"Does it live in the water?\")\n",
      "*   **Branches:** The lines connecting questions to answers. They represent the \"path\" you take based on the answer (e.g., the \"Yes\" or \"No\" path).\n",
      "*   **Decision Nodes:** The questions you ask along the way. (e.g., \"Does it have fur?\")\n",
      "*   **Leaf Nodes:** The final answers or outcomes. This is where you stop asking questions. (e.g., \"It's a Dog,\" \"It's a Cat\").\n",
      "\n",
      "---\n",
      "\n",
      "### How Does the Computer \"Learn\" to Build the Tree?\n",
      "\n",
      "This is the \"machine learning\" part. How does it know which questions to ask and in what order?\n",
      "\n",
      "Imagine you give the computer a table of data about animals you've already identified:\n",
      "\n",
      "| Feature 1: Lives in Water? | Feature 2: Has Fur? | Feature 3: Barks? | **Animal (Label)** |\n",
      "| :---: | :---: | :---: | :--- |\n",
      "| Yes | No | No | Fish |\n",
      "| No | Yes | Yes | Dog |\n",
      "| No | Yes | No | Cat |\n",
      "| Yes | No | No | Dolphin |\n",
      "| No | No | No | Lizard |\n",
      "| No | Yes | Yes | Dog |\n",
      "\n",
      "The computer looks at this data and tries to find the **single best question** it can ask to split the animals into the \"purest\" possible groups.\n",
      "\n",
      "1.  **It tests Question 1: \"Lives in Water?\"**\n",
      "    *   **Yes:** {Fish, Dolphin} -> A pretty pure group (all water animals).\n",
      "    *   **No:** {Dog, Cat, Lizard, Dog} -> A mixed group.\n",
      "\n",
      "2.  **It tests Question 2: \"Has Fur?\"**\n",
      "    *   **Yes:** {Dog, Cat, Dog} -> A pretty pure group (all mammals).\n",
      "    *   **No:** {Fish, Dolphin, Lizard} -> A mixed group.\n",
      "\n",
      "The algorithm uses a mathematical formula (like *Gini Impurity* or *Entropy*) to measure which split creates the most \"purity.\" It picks the question that does the best job. Let's say it picks \"Lives in Water?\" as the root node.\n",
      "\n",
      "Now it has two smaller groups of data. It repeats the *exact same process* for each of those groups.\n",
      "*   For the \"No\" group {Dog, Cat, Lizard, Dog}, it will find that \"Has Fur?\" is the next best question to ask.\n",
      "*   It continues splitting the data over and over until it ends up with leaf nodes that are as pure as possible (e.g., a leaf just for \"Dog\").\n",
      "\n",
      "---\n",
      "\n",
      "### Why are Decision Trees So Popular?\n",
      "\n",
      "**Pros (The Good Stuff):**\n",
      "\n",
      "*   **Easy to Understand:** You can literally look at a decision tree and see exactly how it's making its decisions. This is a huge advantage over \"black box\" models like complex neural networks.\n",
      "*   **Requires Little Data Preparation:** You don't need to do a lot of complex data clean-up before feeding it to a decision tree.\n",
      "*   **Handles Different Data Types:** It works well with both numbers (e.g., age, price) and categories (e.g., color, city).\n",
      "\n",
      "**Cons (The Downsides):**\n",
      "\n",
      "*   **Overfitting:** Sometimes the tree learns the training data *too* well. It becomes a super-specific flowchart that has memorized the data instead of learning the general rules. When it sees new data it's never seen before, it might fail.\n",
      "*   **Instability:** A small change in your data can sometimes cause a completely different tree to be built.\n",
      "\n",
      "### Summary for a Beginner\n",
      "\n",
      "Think of a decision tree as a **flowchart of questions**. The computer learns the best questions to ask by looking at past examples, aiming to create the purest groups at each step until it can make a final, confident decision.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "import google.generativeai as genai\n",
    "\n",
    "# Load your API key from .env file\n",
    "load_dotenv()\n",
    "genai.configure(api_key=os.getenv(\"GEMINI_API_KEY\"))\n",
    "\n",
    "# Initialize the model\n",
    "model = genai.GenerativeModel(\"gemini-2.5-pro\")\n",
    "\n",
    "# Define a prompt\n",
    "prompt = \"Explain decision trees in machine learning in simple terms for beginners.\"\n",
    "\n",
    "# Generate response\n",
    "response = model.generate_content(prompt)\n",
    "\n",
    "# Print result\n",
    "print(\"Gemini Response:\\n\")\n",
    "print(response.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7562105",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
